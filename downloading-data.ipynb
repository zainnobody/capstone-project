{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import zipfile\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "FULL_DATA_DIR = os.path.join(DATA_DIR, \"full-data\")\n",
    "KAGGLE_JSON_PATH = \"kaggle.json\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and cleaning initial data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://github.com/Zdong104/FNSPID_Financial_News_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News & Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading full_history.zip: 100%|██████████| 590M/590M [00:10<00:00, 55.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded: data/full-data/full_history.zip in 11.35 seconds\n",
      "📦 Extracting data/full-data/full_history.zip...\n",
      "✅ Extracted to data/full-data\n",
      "🗑️ Removed: data/full-data/__MACOSX\n",
      "🗑️ Deleted ZIP file: data/full-data/full_history.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading nasdaq_exteral_data.csv: 100%|██████████| 23.2G/23.2G [07:38<00:00, 50.6MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Downloaded: data/full-data/nasdaq_exteral_data.csv in 459.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def download_files(urls):\n",
    "    os.makedirs(FULL_DATA_DIR, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        filename = os.path.basename(url)\n",
    "        filepath = os.path.join(FULL_DATA_DIR, filename)\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(filepath, \"wb\") as f, tqdm(\n",
    "                total=total_size, unit=\"B\", unit_scale=True, desc=f\"Downloading {filename}\"\n",
    "            ) as progress_bar:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "                    progress_bar.update(len(chunk))\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"✅ Downloaded: {filepath} in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "            if filename.endswith(\".zip\"):\n",
    "                extract_zip(filepath)\n",
    "\n",
    "        else:\n",
    "            print(f\"❌ Failed to download: {url}\")\n",
    "\n",
    "def extract_zip(zip_path):\n",
    "    if os.path.exists(zip_path):\n",
    "        print(f\"📦 Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(FULL_DATA_DIR)\n",
    "        print(f\"✅ Extracted to {FULL_DATA_DIR}\")\n",
    "\n",
    "        clean_unwanted_files(FULL_DATA_DIR)\n",
    "        os.remove(zip_path)\n",
    "        print(f\"🗑️ Deleted ZIP file: {zip_path}\")\n",
    "\n",
    "def clean_unwanted_files(directory):\n",
    "    macosx_path = os.path.join(directory, \"__MACOSX\")\n",
    "    if os.path.exists(macosx_path):\n",
    "        shutil.rmtree(macosx_path)\n",
    "        print(f\"🗑️ Removed: {macosx_path}\")\n",
    "\n",
    "urls = [\n",
    "    \"https://huggingface.co/datasets/Zihan1004/FNSPID/resolve/main/Stock_price/full_history.zip\",\n",
    "    \"https://huggingface.co/datasets/Zihan1004/FNSPID/resolve/main/Stock_news/nasdaq_exteral_data.csv\"\n",
    "]\n",
    "\n",
    "download_files(urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bitcoin Historical Data\n",
    "\n",
    "Data source: https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API credentials set up successfully!\n",
      "Downloading mczielinski/bitcoin-historical-data from Kaggle...\n",
      "Dataset URL: https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data\n",
      "✅ Downloaded and extracted: mczielinski/bitcoin-historical-data\n"
     ]
    }
   ],
   "source": [
    "def setup_kaggle_credentials(json_path):\n",
    "    \"\"\"Load and set Kaggle credentials from a local JSON file.\"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"❌ Kaggle credentials file not found at {json_path}\")\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        creds = json.load(f)\n",
    "\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
    "    os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]\n",
    "    print(\"Kaggle API credentials set up successfully!\")\n",
    "\n",
    "def download_kaggle_dataset(dataset):\n",
    "    \"\"\"Download and extract the dataset from Kaggle.\"\"\"\n",
    "    os.makedirs(FULL_DATA_DIR, exist_ok=True)\n",
    "\n",
    "    setup_kaggle_credentials(KAGGLE_JSON_PATH)\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    print(f\"Downloading {dataset} from Kaggle...\")\n",
    "    api.dataset_download_files(dataset, path=FULL_DATA_DIR, unzip=True)\n",
    "    print(f\"✅ Downloaded and extracted: {dataset}\")\n",
    "\n",
    "    clean_unwanted_files(FULL_DATA_DIR)\n",
    "\n",
    "download_kaggle_dataset(\"mczielinski/bitcoin-historical-data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains historical Bitcoin price data recorded at one-minute intervals. The main file included is:\n",
    "- `btcusd_1-min_data.csv`: Contains one-minute price data for Bitcoin, including Open, High, Low, Close (OHLC) prices, volume, and timestamp information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETH\n",
    "\n",
    "Source: https://www.kaggle.com/datasets/prasoonkottarathil/ethereum-historical-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API credentials set up successfully!\n",
      "Downloading prasoonkottarathil/ethereum-historical-dataset from Kaggle...\n",
      "Dataset URL: https://www.kaggle.com/datasets/prasoonkottarathil/ethereum-historical-dataset\n",
      "✅ Downloaded and extracted: prasoonkottarathil/ethereum-historical-dataset\n"
     ]
    }
   ],
   "source": [
    "download_kaggle_dataset(\"prasoonkottarathil/ethereum-historical-dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset provides a collection of Ethereum price data at different time intervals, making it useful for market analysis and trading strategies. It includes three CSV files:\n",
    "\n",
    "- `ETH_1H.csv`: Contains hourly Ethereum price data, including OHLC prices and volume.\n",
    "- `ETH_1min.csv`: Contains one-minute Ethereum price data, similar to Bitcoin's dataset.\n",
    "- `ETH_day.csv`: Contains daily Ethereum price data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
