{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROCESSED_DATA = os.path.join(\"data\", \"processed-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/x0d9sf3x4tn331kv5900b1h80000gn/T/ipykernel_54284/684297744.py:10: DtypeWarning: Columns (0,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  crypto_df = pd.read_csv(combined_file, compression=\"gzip\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# File paths for the processed data files\n",
    "btc_processed_file = os.path.join(PROCESSED_DATA, \"btc_1min_processed.csv.gz\")\n",
    "eth_processed_file = os.path.join(PROCESSED_DATA, \"eth_1min_processed.csv.gz\")\n",
    "combined_file = os.path.join(PROCESSED_DATA, \"crypto_1min_combined.csv.gz\")\n",
    "NEWS_FILTERED_CSV = os.path.join(PROCESSED_DATA, \"aggregated-news_filtered.csv.gz\")\n",
    "\n",
    "# Read the processed CSV files using gzip compression\n",
    "btc_df = pd.read_csv(btc_processed_file, compression=\"gzip\")\n",
    "eth_df = pd.read_csv(eth_processed_file, compression=\"gzip\")\n",
    "crypto_df = pd.read_csv(combined_file, compression=\"gzip\")\n",
    "df_filtered_news = pd.read_csv(NEWS_FILTERED_CSV, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    # Drop rows with invalid/NaT dates\n",
    "    df.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    # Now set and sort index\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "    # Ensure no duplicates\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_based_price_changes_merge_asof(df, offsets, price_col='Close'):\n",
    "    df = df.copy()\n",
    "    df_reset = df.reset_index().rename(columns={'Date': 'time'})\n",
    "    df_reset.sort_values('time', inplace=True)\n",
    "    earliest_time = df_reset[\"time\"].min()\n",
    "    for label, offset_str in offsets:\n",
    "        offset_td = pd.Timedelta(offset_str)\n",
    "        target_col = f\"target_time_{label}\"\n",
    "        df_reset[target_col] = df_reset[\"time\"] - offset_td\n",
    "        temp = df_reset[[\"time\", price_col]].copy()\n",
    "        merged = pd.merge_asof(\n",
    "            df_reset,\n",
    "            temp,\n",
    "            left_on=target_col,\n",
    "            right_on=\"time\",\n",
    "            direction=\"backward\",\n",
    "            suffixes=(\"\", f\"_{label}_ago\")\n",
    "        )\n",
    "        df_reset[f\"{price_col}_{label}_ago\"] = merged[f\"{price_col}_{label}_ago\"]\n",
    "        df_reset.loc[df_reset[target_col] < earliest_time, f\"{price_col}_{label}_ago\"] = np.nan\n",
    "        df_reset[f\"PctChange_{label}\"] = (df_reset[price_col] - df_reset[f\"{price_col}_{label}_ago\"]) / df_reset[f\"{price_col}_{label}_ago\"]\n",
    "        df_reset.drop(columns=[target_col], inplace=True)\n",
    "    df_final = df_reset.set_index(\"time\")\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moving_averages(df, windows=[20, 50, 200], price_col='Close'):\n",
    "    df = df.copy()\n",
    "    for w in windows:\n",
    "        df[f'SMA_{w}'] = df[price_col].rolling(window=w).mean()\n",
    "        df[f'EMA_{w}'] = df[price_col].ewm(span=w, adjust=False).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rsi(df, period=14, price_col='Close', rsi_col='RSI'):\n",
    "    df = df.copy()\n",
    "    delta = df[price_col].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(com=period - 1, min_periods=period).mean()\n",
    "    avg_loss = loss.ewm(com=period - 1, min_periods=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df[rsi_col] = 100 - (100 / (1 + rs))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_macd(df, short=12, long=26, signal=9, price_col='Close'):\n",
    "    df = df.copy()\n",
    "    ema_short = df[price_col].ewm(span=short, adjust=False).mean()\n",
    "    ema_long = df[price_col].ewm(span=long, adjust=False).mean()\n",
    "    df['MACD'] = ema_short - ema_long\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=signal, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bollinger_bands(df, window=20, n_std=2, price_col='Close'):\n",
    "    df = df.copy()\n",
    "    rolling_mean = df[price_col].rolling(window=window).mean()\n",
    "    rolling_std = df[price_col].rolling(window=window).std()\n",
    "    df['BB_Middle'] = rolling_mean\n",
    "    df['BB_Upper'] = rolling_mean + (n_std * rolling_std)\n",
    "    df['BB_Lower'] = rolling_mean - (n_std * rolling_std)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_volume_oscillator(df, short=5, long=20, volume_col='Volume'):\n",
    "    df = df.copy()\n",
    "    df['VolMA_short'] = df[volume_col].rolling(window=short).mean()\n",
    "    df['VolMA_long'] = df[volume_col].rolling(window=long).mean()\n",
    "    df['VolumeOscillator'] = ((df['VolMA_short'] - df['VolMA_long']) / df['VolMA_long']) * 100\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_obv(df, price_col='Close', volume_col='Volume'):\n",
    "    df = df.copy()\n",
    "    df['prev_close'] = df[price_col].shift(1)\n",
    "    obv_vals = [0]\n",
    "    for i in range(1, len(df)):\n",
    "        if df[price_col].iloc[i] > df['prev_close'].iloc[i]:\n",
    "            obv_vals.append(obv_vals[-1] + df[volume_col].iloc[i])\n",
    "        elif df[price_col].iloc[i] < df['prev_close'].iloc[i]:\n",
    "            obv_vals.append(obv_vals[-1] - df[volume_col].iloc[i])\n",
    "        else:\n",
    "            obv_vals.append(obv_vals[-1])\n",
    "    df['OBV'] = obv_vals\n",
    "    df.drop(columns=['prev_close'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_candlestick_patterns(df, open_col='Open', high_col='High', low_col='Low', close_col='Close'):\n",
    "    df = df.copy()\n",
    "    df['candle_range'] = df[high_col] - df[low_col]\n",
    "    df['body_size'] = (df[close_col] - df[open_col]).abs()\n",
    "    df['Doji'] = (df['body_size'] <= 0.1 * df['candle_range']).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atr(df, period=14, high_col='High', low_col='Low', close_col='Close'):\n",
    "    df = df.copy()\n",
    "    df['prev_close'] = df[close_col].shift(1)\n",
    "    df['tr1'] = df[high_col] - df[low_col]\n",
    "    df['tr2'] = (df[high_col] - df['prev_close']).abs()\n",
    "    df['tr3'] = (df[low_col] - df['prev_close']).abs()\n",
    "    df['TR'] = df[['tr1','tr2','tr3']].max(axis=1)\n",
    "    df['ATR'] = df['TR'].ewm(alpha=1/period, adjust=False).mean()\n",
    "    df.drop(columns=['prev_close','tr1','tr2','tr3','TR'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_adx(df, period=14, high_col='High', low_col='Low', close_col='Close'):\n",
    "    df = df.copy()\n",
    "    df['prev_high'] = df[high_col].shift(1)\n",
    "    df['prev_low'] = df[low_col].shift(1)\n",
    "    df['prev_close'] = df[close_col].shift(1)\n",
    "    df['tr1'] = df[high_col] - df[low_col]\n",
    "    df['tr2'] = (df[high_col] - df['prev_close']).abs()\n",
    "    df['tr3'] = (df[low_col] - df['prev_close']).abs()\n",
    "    df['TR'] = df[['tr1','tr2','tr3']].max(axis=1)\n",
    "    df['+DM'] = np.where((df[high_col] - df['prev_high']) > (df['prev_low'] - df[low_col]), \n",
    "                         np.clip(df[high_col] - df['prev_high'], a_min=0, a_max=None), 0)\n",
    "    df['-DM'] = np.where((df['prev_low'] - df[low_col]) > (df[high_col] - df['prev_high']), \n",
    "                         np.clip(df['prev_low'] - df[low_col], a_min=0, a_max=None), 0)\n",
    "    df['TR_ema'] = df['TR'].ewm(alpha=1/period, adjust=False).mean()\n",
    "    df['+DM_ema'] = df['+DM'].ewm(alpha=1/period, adjust=False).mean()\n",
    "    df['-DM_ema'] = df['-DM'].ewm(alpha=1/period, adjust=False).mean()\n",
    "    df['+DI'] = 100 * (df['+DM_ema'] / df['TR_ema'])\n",
    "    df['-DI'] = 100 * (df['-DM_ema'] / df['TR_ema'])\n",
    "    df['DX'] = 100 * ( (df['+DI'] - df['-DI']).abs() / (df['+DI'] + df['-DI']) )\n",
    "    df['ADX'] = df['DX'].ewm(alpha=1/period, adjust=False).mean()\n",
    "    df.drop(columns=['prev_high','prev_low','prev_close','tr1','tr2','tr3','TR','+DM','-DM',\n",
    "                     'TR_ema','+DM_ema','-DM_ema','DX'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stochastic(df, k_window=14, d_window=3, high_col='High', low_col='Low', close_col='Close'):\n",
    "    df = df.copy()\n",
    "    df['roll_low'] = df[low_col].rolling(k_window).min()\n",
    "    df['roll_high'] = df[high_col].rolling(k_window).max()\n",
    "    df['%K'] = 100 * (df[close_col] - df['roll_low']) / (df['roll_high'] - df['roll_low'])\n",
    "    df['%D'] = df['%K'].rolling(d_window).mean()\n",
    "    df.drop(columns=['roll_low','roll_high'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_williams_r(df, period=14, high_col='High', low_col='Low', close_col='Close'):\n",
    "    df = df.copy()\n",
    "    df['roll_high'] = df[high_col].rolling(period).max()\n",
    "    df['roll_low'] = df[low_col].rolling(period).min()\n",
    "    df['Williams_%R'] = -100 * (df['roll_high'] - df[close_col]) / (df['roll_high'] - df['roll_low'])\n",
    "    df.drop(columns=['roll_high','roll_low'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_features(df):\n",
    "    df = df.copy()\n",
    "    df = add_time_based_price_changes_merge_asof(\n",
    "        df, \n",
    "        offsets=[('1m','1min'), ('5m','5min'), ('1h','1h'), ('1d','1d'), ('1w','7d'), ('1mo','30d')],\n",
    "        price_col='Close'\n",
    "    )\n",
    "    df = add_moving_averages(df, windows=[20, 50, 200], price_col='Close')\n",
    "    df = add_rsi(df, period=14, price_col='Close', rsi_col='RSI_14')\n",
    "    df = add_macd(df, short=12, long=26, signal=9, price_col='Close')\n",
    "    df = add_bollinger_bands(df, window=20, n_std=2, price_col='Close')\n",
    "    df = add_volume_oscillator(df, short=5, long=20, volume_col='Volume')\n",
    "    df = add_obv(df, price_col='Close', volume_col='Volume')\n",
    "    df = add_candlestick_patterns(df, open_col='Open', high_col='High', low_col='Low', close_col='Close')\n",
    "    df = add_atr(df, period=14, high_col='High', low_col='Low', close_col='Close')\n",
    "    df = add_adx(df, period=14, high_col='High', low_col='Low', close_col='Close')\n",
    "    df = add_stochastic(df, k_window=14, d_window=3, high_col='High', low_col='Low', close_col='Close')\n",
    "    df = add_williams_r(df, period=14, high_col='High', low_col='Low', close_col='Close')\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df_prepared = prepare_df(btc_df)\n",
    "btc_df_features = add_all_features(btc_df_prepared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_output_file = os.path.join(PROCESSED_DATA, \"btc_1min_with_features.csv.gz\")\n",
    "btc_df_features.to_csv(btc_output_file, index=False, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_processed_file = os.path.join(PROCESSED_DATA, \"eth_1min_processed.csv.gz\")\n",
    "eth_df = pd.read_csv(eth_processed_file, compression=\"gzip\")\n",
    "\n",
    "eth_df_prepared = prepare_df(eth_df)\n",
    "eth_df_features = add_all_features(eth_df_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_output_file = os.path.join(PROCESSED_DATA, \"eth_1min_with_features.csv.gz\")\n",
    "eth_df_features.to_csv(eth_output_file, index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to pull the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing processed data files\n",
    "PROCESSED_DATA = os.path.join(\"data\", \"processed-data\")\n",
    "\n",
    "# File paths for the processed data files WITH features\n",
    "btc_features_file = os.path.join(PROCESSED_DATA, \"btc_1min_with_features.csv.gz\")\n",
    "eth_features_file = os.path.join(PROCESSED_DATA, \"eth_1min_with_features.csv.gz\")\n",
    "\n",
    "# Load the featured data into the correct variables\n",
    "btc_df_features = pd.read_csv(btc_features_file, compression=\"gzip\")\n",
    "eth_df_features = pd.read_csv(eth_features_file, compression=\"gzip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
